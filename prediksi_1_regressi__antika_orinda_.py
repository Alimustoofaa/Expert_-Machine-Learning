# -*- coding: utf-8 -*-
"""PREDIKSI 1  Regressi_ Antika Orinda .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LJydvnLfgm_vFAuSSrl_N9dqa-7dVLgv

# NAMA : ANTIKA ORINDA

# XP : 12.779 

# Path : MLFE 02 SIB Batch 3

Dataset yang digunakan : https://www.kaggle.com/datasets/mirichoi0218/insurance

## Import Module yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
from google.colab import files 
import numpy as np
import pandas as pd
from sklearn.utils import resample 
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder

# Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""## Instal Package Kaggle """

# install kaggle package
!pip install -q kaggle

"""## Upload JSON Profile Kaggle """

# upload kaggle.json
from google.colab import files
files.upload()

"""## Buat direktori dan ubah izin agar bisa memasukkan Json Kaggle """

# make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""## Download Dataset langsung dari Kaggle """

# download dataset, choose 'copy api command' from kaggle dataset
!kaggle datasets download -d mirichoi0218/insurance

"""# Ekstrak ZIP """

# Ekstrak ZIP 
from zipfile import ZipFile
file_name ="/content/insurance.zip"

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print("done")

"""## Memuat Dataset kedalam dataframe menggunakan Pandas"""

# load dataset
import pandas as pd
df = pd.read_csv('/content/insurance.csv')
df.head(10)

df

"""## Mengecek Informasi dari Dataset """

df.info() # mengecek informasi dari dataset

"""##Mengecek stastitik Dataset """

df.describe() # deskripsi stastitik data

"""##Mencari Mising Value """

df.isnull().sum() # Find Missing Values in list Dataset

#Total Number of Missing NA
df.isnull().sum().sum()

"""# Explorisasi Data / Visualisasi Data

##Visualisasikan Outliers pada Fitur Numerik
"""

sns.boxplot(x=df['age']) # visualisasikan data age pada fitur numerik

sns.boxplot(x=df['bmi']) # visualisasikan data bmi pada fitur numerik

sns.boxplot(x=df['children']) # visualisasikan data children pada fitur numerik

sns.boxplot(x=df['charges']) # visualisasikan data charges pada fitur numerik

"""##Menangani Outlier"""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
insurance=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah kita drop outliers
insurance.shape

"""##Pembagian dataset menjadi 2 Fitur yaitu numerical dan kategori"""

numerical_features = ['age','bmi','children','charges'] 
categorical_features = ['sex','smoker','region']

"""## Grouping Visualisasi Fitur Kategori"""

plt.subplots(2, 2, figsize=(20, 16))

for i, col in enumerate(categorical_features):
  plt.subplot(2, 2, i + 1)
  if col == 'smoker':
    df.groupby(col).size().plot(kind='bar', rot=45)
  else:
    df.groupby(col).size().plot(kind='bar', rot=0)

"""##Visualisasi Category Fitur"""

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df1 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df1)
count.plot(kind='bar', title=feature);

feature1 = categorical_features[1]
count1 = df[feature1].value_counts()
percent1 = 100*df[feature1].value_counts(normalize=True)
df2 = pd.DataFrame({'jumlah sampel':count1, 'persentase':percent1.round(1)})
print(df2)
count1.plot(kind='bar', title=feature1);

feature1 = categorical_features[2]
count1 = df[feature1].value_counts()
percent1 = 100*df[feature1].value_counts(normalize=True)
df3 = pd.DataFrame({'jumlah sampel':count1, 'persentase':percent1.round(1)})
print(df3)
count1.plot(kind='bar', title=feature1);

"""##Visualisasi Fitur Numerik"""

df.hist(bins=50, figsize=(20,15))
plt.show()

"""##Exploratory Data Analysis - Multivariate Analysis-

**Categorical Features**

Pada tahap ini, kita akan mengecek rata-rata charges terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap charges.
"""

cat_features = df.select_dtypes(include='object').columns.to_list()
 
for col in cat_features:
  sns.catplot(x=col, y="charges", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="Set3")
  plt.title("Rata-rata 'charges' Relatif terhadap - {}".format(col))

"""**Numerical Features**

Untuk mengamati hubungan antara fitur numerik, kita akan menggunakan fungsi pairplot(). Kita juga akan mengobservasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr(). Tidak perlu menunggu lama, mari kita langsung analisis datanya.
"""

# Mengamati hubungan antar fitur numerik dengan fungsi pairplot()
sns.pairplot(df, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2) # Fungsi Cor -> evaluasi skor korelasi 
 
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

df.drop(['bmi'], inplace=True, axis=1)
df.head()

"""#Data Preparation

##menangani Category Fitur dengan One Hot Encoding
"""

from sklearn.preprocessing import  OneHotEncoder
df = pd.concat([df, pd.get_dummies(df['sex'], prefix='sex')],axis=1)
df = pd.concat([df, pd.get_dummies(df['smoker'], prefix='smoker')],axis=1)
df= pd.concat([df, pd.get_dummies(df['region'], prefix='region')],axis=1)
df.drop(['sex','smoker','region'], axis=1, inplace=True)
df.head()

sns.pairplot(df[['age','children','charges']], plot_kws={"s":3});

df.head()

"""##Teknik PCA dengan tujuan mengurangi reduksi dimensi saat modelling """

from sklearn.decomposition import PCA
 
pca = PCA(n_components=3, random_state=123)
pca.fit(df[['age','children','charges']])
princ_comp = pca.transform(df[['age','children','charges']])

print(pca)

pca.explained_variance_ratio_.round(3)

print (df)

"""## Split dataset dengan ukuran 80:20 """

from sklearn.model_selection import train_test_split
 
X = df.drop(["charges"],axis =1)
y = df["charges"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""##Standarisasi """

from sklearn.preprocessing import StandardScaler
 
numerical_features = ['age','children']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""##Penyiapan dataframe untuk analisis hasil model """

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting','SVM'])

"""# Modelling dengan KNN """

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
 
models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""# Modelling dengan Random Forest """

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""# Modelling dengan Boosting """

from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error

boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## Modelling dengan SVR """

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

svm= SVR()                           
svm.fit(X_train, y_train)
models.loc['train_mse','svm'] = mean_squared_error(y_pred=svm.predict(X_train), y_true=y_train)

"""# Scalling Fitur Numerik """

# Lakukan scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""# Persiapan dan Penghitungan Mean Squared Error masing-masing algoritma"""

# Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting','svm'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting,'svm':svm}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))
 # Panggil mse
mse

mse

"""# Visualiasi chart bar Hasil penghitungan  Mean Squared Error masing-masing algoritma"""

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""## Hasil Prediksi berdasarkan penghitungan  Mean Squared Error masing-masing algoritma"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

pd.DataFrame(pred_dict)