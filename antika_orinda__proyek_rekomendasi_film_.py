# -*- coding: utf-8 -*-
"""Antika Orinda_ Proyek Rekomendasi Film  .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fsk5T2ZsZ9Ssp0zAZqhk8XLizvm-n_Q3

# NAMA : ANTIKA ORINDA

# XP : 12.779 

# Path : MLFE 02 SIB Batch 3 

# Submission : Submission 2 MLFE Terapan -> Sistem Rekomendasi Film

Link dataset :

Moviee lagi : https://www.kaggle.com/datasets/dineshaitham/movies-recommendation-dataset?select=movies.csv

# Import Module yang dibutuhkan
"""

# Commented out IPython magic to ensure Python compatibility.
# Untuk pengolahan data
from google.colab import files 
import numpy as np
import pandas as pd
from sklearn.utils import resample 
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder


# Untuk visualisasi data
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

"""# Install Package Kaggle"""

# install kaggle package
!pip install -q kaggle

"""# Upload JSON Profile Kaggle """

# upload kaggle.json
from google.colab import files
files.upload()

"""# Buat direktori dan ubah izin JSON Kaggle """

# make directory and change permission
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

"""# Download Dataset langsung dari Kaggle """

# download dataset, choose 'copy api command' from kaggle dataset
!kaggle datasets download -d dineshaitham/movies-recommendation-dataset

"""# Unzip File """

# Unzip File 
!unzip /content/movies-recommendation-dataset.zip

"""# Memuat Dataset kedalam dataframe menggunakan Pandas dan mencari nilai unik pada movieId dan userId"""

import pandas as pd

movies = pd.read_csv('/content/movies.csv')
ratings = pd.read_csv('/content/ratings.csv')

print('Jumlah List Movie yang tersedia : ', len(movies.movieId.unique()))
print('Jumlah data Id User yanng terdaftar : ', len(ratings.userId.unique()))

"""# Mengecek Informasi dari Dataset Movie"""

movies.info()

"""# Menampilkan dataframe dataset """

movies

ratings

"""# Mengecek Informasi dari Dataset rating"""

ratings.info()

"""# Mencari nilai unik dan mencetaknya """

print('Banyaknya userId yang terdaftar : ', len(ratings.userId.unique()))
print('banyaknya id movie yang tersedia : ', len(ratings.movieId.unique()))
print('Banyak rating movie yang tersedia : ', len(ratings.rating.unique()))
print('rating judul film yang tersedia : ', ratings.rating.unique())


print('Banyak id movie yang tersedia : ', len(movies.movieId.unique()))
print('Jenis genres film yang tersedia : ', len(movies.genres.unique()))
print('judul film yang tersedia : ', movies.title.unique())

ratings.head()

"""# Mencari nilai missing value"""

ratings.isnull().sum()

movies.isnull().sum()

"""# Menghapus kolom yang tidak berguna"""

ratings.drop('timestamp',axis=1,inplace= True)

ratings.head()

movies.head()

"""# Menampilkan total dari setiap genre"""

count_genre = pd.DataFrame(movies['genres'].value_counts().reset_index().values, columns = ['genre', 'count'])
print(len(count_genre))
pd.options.display.max_colwidth = 500
count_genre.head()

"""# Menggabungkan dataframe rating dengan movie berdasarkan nilai movieID"""

# Menggabungkan dataframe rating dengan movies berdasarkan nilai movieID
movie = pd.merge(movies, ratings , on='movieId', how='left')
movie

"""# Cek missing value dengan fungsi isnull"""

# Cek missing value dengan fungsi isnull()
movie.isnull().sum()

"""# Membersihkan missing value dengan fungsi dropna()"""

# Membersihkan missing value dengan fungsi dropna()
movie_clean = movie.dropna()
movie_clean

"""# Mengecek kembali missing value pada variabel all_movie_clean"""

# Mengecek kembali missing value pada variabel all_resto_clean
movie_clean.isnull().sum()

"""# Menampilkan informasi dataset"""

movie.info()

"""# Membagi dataset menjadi 2 fitur yaitu numerik dan kategori """

numerical_features = ['userId','movieId','rating'] 
categorical_features = ['title','genres']

"""# Menampilkan jumlah sampel dan persentase pada fitur kategori"""

feature = categorical_features[0]
count1 = movie[feature].value_counts()
percent = 100*movie[feature].value_counts(normalize=True)
df1 = pd.DataFrame({'jumlah sampel':count1, 'persentase':percent.round(1)})
print(df1)

feature = categorical_features[1]
count = movie[feature].value_counts()
percent = 100*movie[feature].value_counts(normalize=True)
df2 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df2)

"""#Memvisualisasikan fitur numerik"""

movie.hist(bins=50, figsize=(15,10))
plt.show()

"""# Mengurutkan resto berdasarkan movieID kemudian memasukkannya ke dalam variabel fix_movie"""

# Mengurutkan resto berdasarkan movieID kemudian memasukkannya ke dalam variabel fix_movie
fix_movie = movie_clean.sort_values('movieId', ascending=True)
fix_movie

"""# Mengecek berapa jumlah fix_movie"""

# Mengecek berapa jumlah fix_movie
len(fix_movie.movieId.unique())

"""# Mengecek kategori movie yang unik"""

# Mengecek kategori movie yang unik
fix_movie.title.unique()

"""# Membuang data duplikat pada variabel preparation"""

# Membuang data duplikat pada variabel preparation
preparation_movie = fix_movie.drop_duplicates('movieId')
preparation_movie

"""# Mengonversi data series movieId, title, genre menjadi dalam bentuk list"""

# Mengonversi data series ‘movieID’ menjadi dalam bentuk list
movie_id = preparation_movie['movieId'].tolist()
 
# Mengonversi data series ‘title’ menjadi dalam bentuk list
title_movie = preparation_movie['title'].tolist()
 
# Mengonversi data series ‘genres’ menjadi dalam bentuk list
genres_movie = preparation_movie['genres'].tolist()
 
print(len(movie_id))
print(len(title_movie))
print(len(genres_movie))

"""# Membuat dictionary untuk data movieId, title, genre"""

# Membuat dictionary untuk data ‘movie_ID’, ‘title_Movie’, dan ‘genres_Movie’
movie_new = pd.DataFrame({
    'movie_ID': movie_id,
    'title_Movie': title_movie,
    'genres_Movie': genres_movie
})
movie_new

data = movie_new
data.sample(5)

"""# Menampilkan wordcloud untuk data genre dan title"""

import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter

word_could_dict=Counter(genres_movie)
wordcloud = WordCloud(width = 2000, height = 1000).generate_from_frequencies(word_could_dict)

plt.figure(figsize=(15,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter

word_could_dict=Counter(title_movie)
wordcloud = WordCloud(width = 2000, height = 1000).generate_from_frequencies(word_could_dict)

plt.figure(figsize=(15,8))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()

"""# Melakukan Teknik TF-IDF Vectorizer untuk menemukan representasi fitur penting dari setiap kategori movie dan genre"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data cuisine 
tf.fit(data['title_Movie'])


# Mapping array dari fitur index integer  ke fitur nama 
tf.get_feature_names()

""" # Melakukan fit lalu ditransformasikan ke bentuk matriks kemudian Melihat ukuran matriks tfidf"""

# Melakukan fit lalu ditransformasikan ke bentuk matriks 
tfidf_matrix = tf.fit_transform(data['title_Movie'])

# Melihat ukuran matriks tfidf
tfidf_matrix.shape

"""# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""# Membuat dataframe untuk melihat tf-idf matrix"""

# Membuat dataframe untuk melihat tf-idf matrix
# Kolom diisi dengan jenis get_names
# Baris diisi dengan nama title_Movie
 
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=data.title_Movie
).sample(22, axis=1).sample(10, axis=0)

"""# Menghitung derajat kesamaan (similarity degree) antar movie dengan teknik cosine similarity

# Menghitung cosine similarity pada matrix tf-idf
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa movie kemudian melihat similarity matrix pada setiap movie"""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa movie
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['genres_Movie'], columns=data['title_Movie'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap movie
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""# Mendapatkan rekomendasi"""

def movie_recommendations(title_Movie, similarity_data=cosine_sim_df, items=data[['title_Movie', 'genres_Movie']], k=5):
    """
    Rekomendasi Resto berdasarkan kemiripan dataframe
 
    Parameter:
    ---
    nama_resto : tipe data string (str)
                Nama Restoran (index kemiripan dataframe)
    similarity_data : tipe data pd.DataFrame (object)
                      Kesamaan dataframe, simetrik, dengan resto sebagai 
                      indeks dan kolom
    items : tipe data pd.DataFrame (object)
            Mengandung kedua nama dan fitur lainnya yang digunakan untuk mendefinisikan kemiripan
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---
 
 
    Pada index ini, kita mengambil k dengan nilai similarity terbesar 
    pada index matrix yang diberikan (i).
    """
 
 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,title_Movie].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(title_Movie, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""# Rekomendasi berdasarkan film"""

data[data.title_Movie.eq('The Greatest Showman (2017)')]

"""# Rekomendasi berdasarkan genre"""

data[data.genres_Movie.eq('Drama')]

"""# list Rekomendasi berdasarkan  genre yang mirip """

indices = pd.Series(index = data['genres_Movie'], data = data.index).drop_duplicates()
indices.head()

"""# List rekomendasi berdasarkan kemiripan dengan judul film """

rekomendasi = pd.DataFrame(movie_recommendations('The Greatest Showman (2017)'))
rekomendasi

"""# list  jumlah genre yang mirip atau serupa"""

value = pd.DataFrame(rekomendasi['genres_Movie'].value_counts().reset_index().values, columns = ['genres_Movie', 'count'])
value.head()

"""# Evaluasi model """

TP = 5 #jumlah prediksi benar untuk genre yang mirip atau serupa
FP = 0 #jumlah prediksi salah untuk genre yang mirip atau serupa

Precision = TP/(TP+FP)
print("{0:.0%}".format(Precision))

"""# Model Development dengan Collaborative Filtering

# Import library
"""

# Import library
import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""# Data understanding pada ratings csv"""

# Membaca dataset
 
df = ratings
df

"""# Menyandikan (encode) fitur ‘userID ’ dan ’ movieID’ ke dalam indeks integer dengan cara mengubah userID dan movie menjadi list tanpa nilai yang sama, melakukan encoding userID dan movieID serta melakukan proses encoding angka ke userID dan movieID"""

# Mengubah userID menjadi list tanpa nilai yang sama 

user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

# melakukan encoding userID 
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# melakukan proses encoding angka ke userID 
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah userID menjadi list tanpa nilai yang sama 

movie_ids = df['movieId'].unique().tolist()
print('list movieID: ', movie_ids)

# melakukan encoding userID 
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded movieID : ', movie_to_movie_encoded)

# melakukan proses encoding angka ke userID 
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke movieID: ', movie_encoded_to_movie)

# Mengubah movieID menjadi list tanpa nilai yang sama 
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieID 
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
 
# Melakukan proses encoding angka ke movieID
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

"""# Memetakan ‘userID’ dan ‘movieID’ ke dataframe yang berkaitan."""

# Mapping userID ke dataframe user
df['user'] = df['userId'].map(user_to_user_encoded)
 
# Mapping placeID ke dataframe resto
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

"""# Mengecek beberapa hal dalam data seperti jumlah user, jumlah movie, kemudian mengubah nilai rating menjadi float, mendapatkan nilai rating minimum dan maximum"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# Mendapatkan jumlah resto
num_movie = len(movie_encoded_to_movie)
print(num_movie)
 
# Mengubah rating menjadi nilai float
df['rating'] = df['rating'].values.astype(np.float32)
 
# Nilai minimum rating
min_rating = min(df['rating'])
 
# Nilai maksimal rating
max_rating = max(df['rating'])
 
print('Number of User: {}, Number of Resto: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""# Mengacak dataset agar distribusi menjadi random"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""# Membuat variabel x untuk mencocokkan data user dan movie menjadi satu value dan y untuk membuat rating dari hasil Kemudian melakukan Pembagian data menjadi data training dan validasi"""

# Membuat variabel x untuk mencocokkan data user dan resto menjadi satu value
x = df[['user', 'movie']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""# pembuatan model untuk  menghitung skor kecocokan antara pengguna dan movie dengan teknik embedding."""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings resto
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding resto bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""# proses compile pada model"""

model = RecommenderNet(num_users, num_movie, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""# proses training model """

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""# Membuat kelas untuk mengambil sampel user secara acak dan definisikan variabel movie_not_visited sebagai sebagai daftar movie untuk direkomendasikan pada pengguna."""

movie_df = movie_new
df = pd.read_csv('ratings.csv')
# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movie_visited_by_user = df[df.userId== user_id]
 
# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html 
movie_not_visited = movie_df[~movie_df['movie_ID'].isin(movie_visited_by_user.userId.values)]['movie_ID'] 
movie_not_visited = list(
    set(movie_not_visited)
    .intersection(set(movie_to_movie_encoded.keys()))
)
movie_not_visited = [[movie_to_movie_encoded.get(x)] for x in movie_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_visited), movie_not_visited)
)

movie_df = movie_new
df = pd.read_csv('ratings.csv')
# Mengambil sample user
user_id = df.userId.sample(1).iloc[0]
movie_visited_by_user = df[df.userId== user_id]
 
# Operator bitwise (~), bisa diketahui di sini https://docs.python.org/3/reference/expressions.html 
movie_not_visited = movie_df[~movie_df['movie_ID'].isin(movie_visited_by_user.userId.values)]['movie_ID'] 
movie_not_visited = list(
    set(movie_not_visited)
    .intersection(set(movie_to_movie_encoded.keys()))
)
movie_not_visited = [[movie_to_movie_encoded.get(x)] for x in movie_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_visited), movie_not_visited)
)

"""# memperoleh rekomendasi restoran, gunakan fungsi model.predict() dari library Keras"""

ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-20:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_visited[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(movie))
print('===' * 9)
print('Movie with high ratings from user')
print('----' * 8)
 
top_movie_user = (
    movie_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movie_df[movie_df['movie_ID'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title_Movie, ':', row.genres_Movie)
 
print('----' * 8)
print('Top 20 movie recommendation')
print('----' * 8)
 
recommended_movie = movie_df[movie_df['movie_ID'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title_Movie, ':', row.genres_Movie)

"""# Visualisasi plot metrik evaluasi dengan matplotlib"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""# Evaluasi model """

model.evaluate(x,y)

"""Observasi :
Pada gambar diatas  menunjukkan bahwa model mempunyai nilai _root_mean_squared_error sebesar 0.21 dengan nilai loss yang diperoleh sebanyak 0.62 , hasil tersebut sudah cukup bagus karena dengan nilai root_mean_squared_error sebesar 0.21 berarti perbedaan nilai dari prediksi sebuah model sebagai estimasi atas nilai yang diobservasi sebesar 0.21
"""